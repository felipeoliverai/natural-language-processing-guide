{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "custom_tagger.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYDemn8-Dyam"
      },
      "source": [
        "### Custom Tagger \r\n",
        "\r\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jneFj7WDveD",
        "outputId": "fefc5d32-a6ef-4257-cbec-b3921ee4dfa1"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFHD0uEzD2gF"
      },
      "source": [
        "# Recebe um texto como input e imprime cada palavra com uma tag default\r\n",
        "def learnDefaultTagger(simpleSentence):\r\n",
        "    # Tokenização\r\n",
        "    wordsInSentence = nltk.word_tokenize(simpleSentence)\r\n",
        "\r\n",
        "    # Etiquetador\r\n",
        "    tagger = nltk.DefaultTagger(\"NN\")\r\n",
        "\r\n",
        "    # Aplicando o Etiquetador ao conjunto de palavras\r\n",
        "    posEnabledTags = tagger.tag(wordsInSentence)\r\n",
        "    print(\"\\nPalavras com a tag default\")\r\n",
        "    print(posEnabledTags)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm9AwjV1D3Ep"
      },
      "source": [
        "# Recebe um texto como input e imprime a lista de tokens com as tags definidas usando expressões regulares\r\n",
        "def learnRETagger(simpleSentence):\r\n",
        "    customPatterns = [\r\n",
        "        (r'.*ing$', 'ADJECTIVE'),             \r\n",
        "        (r'.*ly$', 'ADVERB'),                 \r\n",
        "        (r'.*ion$', 'NOUN'),                  \r\n",
        "        (r'(.*ate|.*en|is)$', 'VERB'),        \r\n",
        "        (r'^an$', 'INDEFINITE-ARTICLE'),      \r\n",
        "        (r'^(with|on|at)$', 'PREPOSITION'),   \r\n",
        "        (r'^\\-?[0-9]+(\\.[0-9]+)$', 'NUMBER'), \r\n",
        "        (r'.*$', None),\r\n",
        "    ]\r\n",
        "\r\n",
        "\r\n",
        "    # Etiquetador\r\n",
        "    tagger = nltk.RegexpTagger(customPatterns)\r\n",
        "\r\n",
        "    # Tokenização\r\n",
        "    wordsInSentence = nltk.word_tokenize(simpleSentence)\r\n",
        "\r\n",
        "    # Aplicando o Etiquetador ao conjunto de palavras\r\n",
        "    posEnabledTags = tagger.tag(wordsInSentence)\r\n",
        "    print(\"\\nPalavras com a tag definida por expressões regulares\")\r\n",
        "    print(posEnabledTags)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNdNyHuJD9oc"
      },
      "source": [
        "# Recebe um texto como input e imprime a lista de tokens com as tags definidas usando expressões regulares\r\n",
        "def learnLookupTagger(simpleSentence):\r\n",
        "    mapping = {\r\n",
        "        '.': '.', 'place': 'NN', 'on': 'IN',\r\n",
        "        'earth': 'NN', 'Mysore' : 'NNP', 'is': 'VBZ',\r\n",
        "        'an': 'DT', 'amazing': 'JJ'\r\n",
        "    }\r\n",
        "\r\n",
        "    # Etiquetador\r\n",
        "    tagger = nltk.UnigramTagger(model=mapping)\r\n",
        "\r\n",
        "    # Tokenização\r\n",
        "    wordsInSentence = nltk.word_tokenize(simpleSentence)\r\n",
        "\r\n",
        "    # Aplicando o Etiquetador ao conjunto de palavras\r\n",
        "    posEnabledTags = tagger.tag(wordsInSentence)\r\n",
        "    print(\"\\nPalavras com a tag definida por mapeamento\")\r\n",
        "    print(posEnabledTags)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yveKh9sgEKSq",
        "outputId": "5f7b9e39-d19a-43d2-ba8f-f21254b0d208"
      },
      "source": [
        "# Executa o programa\r\n",
        "if __name__ == '__main__':\r\n",
        "    testSentence = \"London is an amazing place on earth. I have London 10 times.\"\r\n",
        "    learnDefaultTagger(testSentence)\r\n",
        "    learnRETagger(testSentence)\r\n",
        "    learnLookupTagger(testSentence)\r\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Palavras com a tag default\n",
            "[('London', 'NN'), ('is', 'NN'), ('an', 'NN'), ('amazing', 'NN'), ('place', 'NN'), ('on', 'NN'), ('earth', 'NN'), ('.', 'NN'), ('I', 'NN'), ('have', 'NN'), ('London', 'NN'), ('10', 'NN'), ('times', 'NN'), ('.', 'NN')]\n",
            "\n",
            "Palavras com a tag definida por expressões regulares\n",
            "[('London', None), ('is', 'VERB'), ('an', 'INDEFINITE-ARTICLE'), ('amazing', 'ADJECTIVE'), ('place', None), ('on', 'PREPOSITION'), ('earth', None), ('.', None), ('I', None), ('have', None), ('London', None), ('10', None), ('times', None), ('.', None)]\n",
            "\n",
            "Palavras com a tag definida por mapeamento\n",
            "[('London', None), ('is', 'VBZ'), ('an', 'DT'), ('amazing', 'JJ'), ('place', 'NN'), ('on', 'IN'), ('earth', 'NN'), ('.', '.'), ('I', None), ('have', None), ('London', None), ('10', None), ('times', None), ('.', '.')]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pu8KpV6UEQss"
      },
      "source": [
        "<br>\r\n",
        "<hr>"
      ]
    }
  ]
}